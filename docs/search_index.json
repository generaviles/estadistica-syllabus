[
["index.html", "Estadística para el Análisis de Datos Capítulo 1 Introducción", " Estadística para el Análisis de Datos Gener Avilés R 2017-03-13 Capítulo 1 Introducción Curso impartido por: Dr. Juan Iván Nieto Hipólito Dra. María de los Ángeles Cosío León "],
["conceptos-generales.html", "Capítulo 2 Conceptos Generales 2.1 Terms comparing statistics and computer sciences 2.2 Teoria de Conjuntos 2.3 Diagramas de Venn 2.4 Algebra de Conjuntos 2.5 Leyes de Morgan 2.6 Modelos De Probabilidad 2.7 Probabilidad Condicional", " Capítulo 2 Conceptos Generales 7 de Febrero 2017 Cuando se tiene un modelo conocido que se asemeja al conjunto de datos, se le llama modelo parametrico. P.ej: \\[\\int_{a}^{b} f(x)dx\\] La robustez del modelo la da el coeficiente de correlacion (\\(R^2\\)), el cual nos habla de que tanto se parece el modelo a los datos. los valores van de \\(0-1\\), un valor \\(&gt;0.9\\) se considera adecuado. Cunado los datos no se parecen a un modelo ya conocido, se utilizan los modelos no parametricos. 2.1 Terms comparing statistics and computer sciences 2.2 Teoria de Conjuntos 2.2.1 Definiciones Conjunto: Una coleccion de elementos con caracteristicas que comparten entre ellos. \\[A=\\text{{1,2,3,4}}\\] \\[B = \\text{{numeros enteros positivos}}\\] \\[ C = \\text{{numeros enteros &gt; 3}} = \\text{{4,5,6...}}\\] Todos estos tipos de conjuntos se pueden convertir eventualmente en el espacio muestral, por lo tanto la definicion del espacio muestral es vital antes de iniciar procesos de anlalisis. Alternativamente, los elementos \\(x\\) de un conjunto se pueden enunciar de tal manera que cumplan una caracteristica \\(P\\). \\[\\text{{x|x satisface P}}\\] En esta notacion, el simbolo \\(|\\) se interpreta como: “tal que”. Otro ejemplo con esta notacion: \\[ E = \\{x|x \\space numero\\space entero\\space 4 \\leq x \\leq 10\\}\\] Pertenece a (\\(\\in\\)): Tomando el ejemplo anterior, podemos decir que \\(x = 5 \\in E\\). No pertenece a (\\(\\notin\\)) Tomando el ejemplo anterior podemos decir que \\(x = 11 \\notin E\\) Subconjunto (\\(\\subset\\)) Cuando todos los elementos del conjunto \\(A\\) estan incluidos en el conjunto \\(B\\) (\\(A \\subset B\\)) Complemento (\\(^c\\)) El complemento de un conjunto \\(S\\), con respecto al conjunto universo (\\(\\Omega\\)), otros autores utilizan \\(U\\), es el conjunto de todos los elementos que no pertenecen a \\(S\\), y se denota como \\(S^c\\). Es importante recordar que \\(\\Omega^c = \\emptyset\\) donde \\(\\emptyset\\) es el conjunto vacio. Union (\\(\\cup\\)) \\[S \\cup T = \\{x|x \\in or\\space x\\in T\\}\\] Intereseccion (\\(\\cap\\)) \\[S \\cap T = \\{x|x \\in S\\space y \\space x \\in T \\} \\] Por lo tanto: \\[\\bigcup_{n=1}^{\\infty}= S_1 \\cup S_2 \\cup ...= \\{ x|x \\in S_n para \\space alguna\\space n\\} \\] Donde \\(para\\space S_n = \\space un \\space entero \\space positivo\\). \\[ \\bigcap_{n=1}^{\\infty} = S_1 \\cap S_2 \\cap ... = \\{ x|x \\in S_n \\space para \\space alguna \\space n\\}\\] 2.2.2 Conjuntos Disjuntos Son aquellos cuya interseccion (\\(\\cap\\)) es el conjunto vacio (\\(\\emptyset\\)). No se intersectan. \\[S \\cap T = \\{ \\emptyset\\}\\] La probabilidad del conjunto vacio no es igual a \\(\\emptyset\\), por lo tanto habra que calcularla en cada caso. 2.2.3 Partición: Una colección de conjuntos se dice que es una particion de un conjunto \\(S\\) si los conjuntos en la coleccion son disjuntos y su union es \\(S\\). \\[S = \\{1,2,3,4,5,6,7,8\\}\\] \\(A = \\{1,2,3\\}\\), \\(B = \\{4,5,6,7,8\\}\\) y \\(C = \\{\\emptyset\\}\\) Ojo: simpre considerar la probabilidad del conjunto vacio, siempre existe. Si \\(x\\) y \\(y\\) son 2 objetos \\((x,y)\\) para describir un par ordenado, por ejemplo, numeros reales \\(R\\), el conjunto de pares (o tripleta) de escalares se puede escribir como \\(R^2\\) y \\(R^3\\), respectivamente. 2.3 Diagramas de Venn \\(A \\cap B\\) \\(A\\cup B\\) \\(A^c \\cap B\\) \\(\\text{Conjuntos Disjuntos}\\) \\(S,T,\\space y \\space V \\space son \\space una \\space particion \\space de \\space \\Omega\\) 2.4 Algebra de Conjuntos Propiedad asociativa ???? \\[S \\cup T = T \\cup S\\] \\[S \\cap (T \\cup V) = (S \\cap T) \\cup (S \\cap V)\\] \\[(S^c)^c = S\\] \\[S \\cup \\Omega = \\Omega\\] Propiedad Distributiva???? \\[S \\cup (T \\cup V) = (S \\cup T)\\cup V\\] \\[S \\cup (T \\cap V) = (S \\cup T)\\cap (S \\cap V)\\] \\[S \\cap S^c = \\emptyset\\] \\[S \\cap \\Omega = S\\] 2.5 Leyes de Morgan Considerar las siguentes notaciones: \\((\\bigcup_{n}^{}S_n)^c = \\bigcap_{n}^{}{S_n}^c\\) \\((\\bigcap S_n)^2 = \\bigcup_{n}^{}{S_n}^c\\) *Notar como cambian de \\(\\cup\\) a \\(\\cap\\) y viceversa, en estas leyes. 8 de Febrero de 2017 2.6 Modelos De Probabilidad Buscan proveer certidumbre o reducir incertidumbre. 2.6.1 Elementos de un Modelo de Probabilidad El espacio muestral (\\(\\Omega\\)): Entendido como el conjunto de todos los posibles resultados de un experimento. Ley de probabilidad, la cual asigna a un conjunto \\(A\\) de posibles resultados (llamdo también evento) un número no-negativo (\\(P(A) = (\\text{la probabilidad de A})\\)) que codifica nuestro conocimiento o creencia sobre la probabilidad de los elementos de \\(A\\). 2.6.2 Axiomas de Probabilidad No negatividad Para cada uno de los eventos en \\(A\\): \\(P(A) \\geq 0\\) Adición Si \\(A\\) y \\(B\\) son dos eventos disjuntos, entonces la posibilidad de su unión satisface: \\(P(A \\cup B) = P(A)+P(B)\\) ó \\(P(A_1\\cup A_2 \\cup ...A_n) = P(A_1) + P(A_2)+...P(A_n)\\) Normalización La probabilidad del copmleto (entire) espacio muestral \\(\\Omega\\) es \\(1\\), esto es \\(P(\\Omega) = 1\\). Ojo: Los eventos del espacio muestral deben ser eventos mutuamente excluyentes, osea que no puedan suceder simultaneamente. 2.6.3 Ley de Probabilidad Discreta Probabilidad discreta: Asignar a un evento una probabilidad única (valor). Si el espacio de probabilidad consiste de un número finito de posibles resultados, entonces la ley de probabilidad se especifica por las probabilidades de cada uno de los eventos. En particular, la probabilidad de cualquier evento. \\(\\{S_1,S_2,...S_n\\}\\) es la suma de las probabilidades de sus elementos: \\[P(\\{S_1,S_2,...S_n\\}) = P(S_1)+P(S_2)+...+P(S_n)\\] 2.6.4 Ley de Probabilidad Discreta Uniforme Si el espacio muestral consiste de \\(n\\) posibles resultados con igual probabilidad de ocurrencia, entonces la probabilidad de cualquier evneto \\(A\\), está dada por: \\[P(A)= \\frac{\\text{Número de elementos de A}}{n}\\] 2.6.5 Función Densidad de Probabilidad También conocida como Probability Density Function (pdf) o Probability Mass Function (pmf). Para una variable aleatoria o evento discreto, se define como: \\[f(x) = P(X=x)\\] 2.6.6 Acumulativa pdf (Comulative pdf) Se define como la suma de los resultados parcials de los eventos que validan el experimento: \\[cpdf = \\sum_{i}(P(x_i=x))\\] Para los \\(x_i\\) que validan el experimento. 14 de Febrero 2017 2.7 Probabilidad Condicional La siguiente ecuación: \\[P(A/B) = \\frac{P(A\\cap B)}{P(B)}\\] Puede también ser expresada en los términos de probabilidad condicional secuencial: \\[P(A\\cap B) = P(A/B)*P(B)\\] Siempre y cuando \\(P(B)&gt;0\\) Si los posibles resultados tienen la misma probabilidad de ocurrencia entonces: \\[P(A/B) = \\frac{\\text{No. de elementos en } A\\cap B}{\\text{No. de elementos en }B}\\] Importante: El conjunto universo en la probabilidad condicional (dado un evento anterior) cambia de \\(\\Omega\\) al subconjunto \\(B\\). 2.7.0.1 Ejemplos: Considerar el lanzamiento de 2 dados: \\[A = \\{\\text{la suma es}\\geq 8 \\space y \\space \\leq 10\\}\\] \\[B = \\{\\text{el dado 1}=6 \\} \\therefore P(B) = \\frac {1}{6}\\] Recordando los conceptos de combinaciones: \\(C = n^m\\) cuando \\(n\\) es el número de posibles resultados y \\(m\\), el número de experimentos. para éste ejemplo en particular las combinaciones posibles son \\(6^2 = 36\\), entonces: \\[P(A\\cap B) = \\frac {3}{36} \\therefore P(A/B) = \\frac {\\frac {3}{36}}{\\frac {1}{6}} = \\frac {18}{36} = \\frac {1}{2}\\] Es importante que la probabilidad condicional es mayor a la probabilidad independiente de previos eventos, porque el universo en la condicional disminuye de \\(\\Omega\\) a un subconjunto, en éste caso \\(B\\). La probabilidad de que, al lanzar los dados del ejemplo anterior, la suma sea \\(\\geq 8\\) y \\(\\leq 10\\) ó \\(A = \\{\\geq 8 \\space y \\space \\leq 10\\}.\\) A ésta probabilidad la denotaremos como \\(P(A)\\), al realizar el experimento manual obtenemos la siguiente imagen: Se puede observar que se han indicado las combinaciones que cumplen con una suma \\(\\geq 8\\) y \\(\\leq 10\\) ó \\(A = \\{\\geq 8 \\space y \\space \\leq 10\\}\\). Por lo tanto: \\[P(A) = \\frac {12}{36} = \\frac {1}{3}\\]. Otra manera de entender éste concepto es visualizarlo a través de una matriz: Con la visualización, es sencillo llegar a la conclusión \\(A = \\frac {12}{36} = \\frac {1}{3}\\) En el lanzamiento sucesivo de 3 monedas, queremos saber la probabilidad condicional, \\(P(A/B)\\), cuando \\(A\\) y \\(B\\) son los eventos: \\[A = \\{\\text{aparecen más soles que águilas}\\}\\] \\[B = \\{\\text{el primer lanzamiento cae sol}\\}\\] La visualización de todas las posibilidades de éste fenómeno se puede apreciar en la siguiente figura: Derivado del árbol en la imagen se pueden determinar las probabilidades de los siguientes subconjuntos: \\[P(A) = \\{\\text{sss, ssa, sas, ass }\\} = \\frac {4}{8} = \\frac {1}{2}\\] \\[P(B) = \\{\\text{sss, ssa, sas, saa}\\} = \\frac{4}{8} = \\frac{1}{2}\\] \\[P(A\\cap B) = \\{\\text{sss, ssa, sas}\\} = \\frac{3}{8}\\] \\[\\therefore\\] \\[P(A/B) = \\frac {P(A\\cap B)}{P(B)} = \\frac {\\frac {3}{8}}{\\frac {1}{2}} = \\frac {6}{8} = \\frac {3}{4}\\] Nótese el la mayor probabilidad de \\(P(A/B)\\) dado que el universo pasó de ser \\(\\Omega\\) al subconjunto \\(B\\). 2.7.1 Repaso de combinaciones y permutaciones La cantidad total de combinaciones posibles en un experimento se puede calcular como \\(n^m\\) donde: \\[n = \\text{posibles resutlados}\\] \\[m = \\text{número de experimentos a realizar}\\] Cuando de un número de combinaciones se elige una muestra \\(r\\) y el orden en el que éstas se elige no importa (combinaciones): \\[P = \\left( \\begin{array}{c} n \\\\ r \\end{array} \\right) = \\frac {n!}{r!(n-r)!}\\] Cuando de un numero de combinaciones se elige una muestra \\(r\\) y el orden en el que ésta se elige SI importa (permutaciones): \\[P = \\left( \\begin{array}{c} n \\\\ r \\end{array} \\right) = \\frac {n!}{(n-r)!}\\] 2.7.1.1 Ejemplo: Al lanzar 8 dados, ¿cuántas combinaciones diferentes son posibles? \\[C = 6^8\\] PENDIENTE REVISAR- Si elijo el resultado de 2 dados de los 8 lanzados, ¿de cuántas maneras distintas los puedo elegir?: \\[P = \\left( \\begin{array}{c} 8 \\\\ 2 \\end{array} \\right) = \\frac {n!}{r!(n-r)!}\\] Siempre y cuando \\(A_1\\) y \\(A_2\\) sean eventos disjuntos (\\(P(A_1\\cap A_2) = \\emptyset\\)) podemos entonces decir que: \\[P = (A_1 \\cap A_2 \\vert B) = \\frac {P(A_1 \\cap B)}{P(B)}+ \\frac {P(A_2 \\cap B)}{P(B)} = P(A_1/B) + P(A_2/B)\\] 2.7.1.2 Ejemplo Tomando datos del experimento anterior con monedas: \\[A_1 = \\{\\text{aparecen más soles que águilas}\\} = \\{\\text{sss, ssa, sas, ass}\\}\\] \\[A_2 = \\{\\text{aparecen más águilas que soles}\\} = \\{\\text{ssa, asa, aas, aaa}\\}\\] \\[B = \\{\\text{el primer lanzamiento es sol}\\} = \\{\\text{sss, ssa, sas, saa}\\}\\] \\[A_1 \\cap A_2 = \\{\\emptyset\\}\\] \\[\\therefore\\] \\[P(A_1) = \\frac {4}{8} = \\frac {1}{4}\\space \\&amp; \\space P(A_2) = \\frac {4}{8} = \\frac {1}{4}\\] \\[P(A_1\\cap B) = \\frac{3}{8}\\] \\[P(A_2\\cap B) = \\frac{1}{8}\\] \\[P(A_1\\cup A_2\\vert B) = \\frac {\\frac{3}{8}}{\\frac{1}{2}} + \\frac{\\frac{1}{8}}{\\frac{1}{2}} = \\frac{6}{8} + \\frac{2}{8} = 1\\] \\[P(A_1\\cup A_2\\vert B) = 1 \\space \\therefore\\] \\[P(A_1\\cup A_2...\\cup A_i \\vert B) = P(A_1/B) + P(A_2/B)+...+ P(A_i/B)\\] Siempre y cuando \\(\\{A_1\\cap A_2...\\cap A_i\\}= \\emptyset\\). 2.7.2 Independencia Si: \\[P(A\\cap B) = P(A)*P(B)\\] Se dice que \\(A\\) y \\(B\\) son eventos independientes. Distinto a ser eventos disjuntos: \\(P(A\\cap B) = \\emptyset\\). Entonces, asumiendo independencia obetnemos: \\[P(A/B) = \\frac {P(A\\cap B)}{P(B)} = \\frac{P(A)P(B)}{P(B)} = P(A)\\] La ecuación anterior demuestra que, los eventos independientes no afectan la probabilidad uno del otro. "],
["recoleccion-de-datos.html", "Capítulo 3 Recolección de Datos 3.1 Definiciones 3.2 Tipos de Muestreo 3.3 Tipos de Estudios", " Capítulo 3 Recolección de Datos 3.1 Definiciones A primary goal of statistical studies is to collect data that can then be used to make informed decisions. It should come as no surprise that the ability to make good decisions depends on the quality of the information available. Datos: colección de información sobre las variables de interés. Para poder tener una colección habrá que definir la población de donde saldrán éstos datos: Población: Conjunto de datos, objetos, humanos, experiencias, étc. Población infinita: Aquella que no se puede o es difícil de contar. (población difícil o no contable) Población finita: se puede contar y/o medir. Población muestreada: subconjunto de la población que reúne todas las características (parámetros) de la población. Parámetro: unidad de medida de los atributos, características de la población. Muestra: Subconjunto de la población. Estadísticos: unidad de medida de un atributo o característica de la muestra. Censo: cuando la población se analiza en su totalidad. A study is an observational study if the investigator observes characteristics of a sample selected from one or more existing populations. The goal of an observational study is usually to draw conclusions about the corresponding population or about differences between two or more populations. In a well-designed observational study, the sample is selected in a way that is designed to produce a sample that is representative of the population. A study is an experiment if the investigator observes how a response variable behaves when one or more explanatory variables, also called factors, are manipulated. The usual goal of an experiment is to determine the effect of the manipulated explanatory variables (factors) on the response variable. In a well-designed experiment, the composition of the groups that will be exposed to different experimental conditions is determined by random assignment. 3.2 Tipos de Muestreo Advantages of sampling methods: Reduced cost. Greater speed. Greater Scope Greater Accuracy 3.2.0.1 Types of sampling 3.2.0.1.1 Non Probabilistic Techniques Muestreo por Conveniencia: Los encuestados son seleccionados porque estaban en el lugar preciso en el momento adecuado. Muestreo por Juicio: Los encuestados son seleccionados siguiendo el criterio del investigador, basándose en su conocimiento de la población objetivo. Muestreo Encadenado: Se selecciona a una muestra que sirve como punto de partida para otra muestra. Se utiliza cuando, por la naturaleza delicada de la pregunta o la dificultad de encontrar a los encuestados, es necesario que el encuestado nos dirija a otro. Un ejemplo típico de la utilidad de este método sería la investigación sobre hábitos de conducta moralmente no aceptados por la sociedad. Muestreo por Cuotas: En este caso el investigador tiene una información más detallada de la distribución de la población según algunas variables que están relacionadas con la variable a estudiar. De acuerdo con estas variables se divide la población en estratos y se entrevista un número determinado en cada estrato. 3.2.0.1.2 Probabilistic Techniques Muestreo Aleatorio Simple (MAS): Cada elemento de la población y cada posible muestra de un tamaño n tienen una probabilidad conocida e igual de ser seleccionados. Esta técnica requiere tener un listado exhaustivo de todos los elementos de la población objetivo. Errores que arruinan el muestreo aleatorio simple (buscar evitarlos siempre): Tendencias. Prejuicios. Parcialidades. Muestreo Sistemático: Se elige un primer elemento aleatoriamente y a continuación todos los siguientes cada n posiciones. Así, si por ejemplo queremos seleccionar 20 individuos de entre 100, el primer paso es seleccionar un número aleatorio entre 1 y 5 (ya que 100/20=5), digamos el 3; a continuación seleccionamos los individuos 3, 8, 13, 18,… 93, 98. Esto implica la ordenación de todos los elementos de la población, si bien el criterio de ordenación no debe guardar ninguna relación con el fenómeno sociológico a estudiar. Muestreo Estratificado: Requiere al menos dos etapas. En una primera etapa la población objetivo se divide en estratos según las variables que se consideran relacionadas con el fenómeno sociológico a estudiar. La segunda fase consiste en seleccionar aleatoriamente una muestra dentro de cada estrato. Muestreo por conglomerados (clusters): Monoetápico: La población es dividida en conglomerados (barrios, manzanas), seleccionando un grupo de ellos con probabilidad proporcional a su importancia. Una vez se tienen estos conglomerados se encuesta a todos los elementos del conglomerado (todos los vecinos de las manzanas B, H y G). Bietápico: Igual que el anterior pero en lugar de encuestar a todos los elementos del conglomerado se selecciona una muestra. 1-in-\\(k\\) systematic sampling/ muestreo sistemático 1-en-\\(k\\): Consiste en seleccionar cada \\(k\\)-ésima unidad. Útil para muestreo de artículos en líneas de producción. Ejemplos: Muestreo con reemplazo: En un lote de 1000 artículos. Agarro 20 al hazar, si \\(\\leq 4\\) están defectuosos, acepto el lote. Muestreo sin remplazo: Después de sacar 20, vuelvo a muestrear a los 980 restantes (con ésta técnica la muestra aumenta, dado que \\(\\Omega\\) disminuye y la cantidad de artículos defectuosos siguen siendo los mismos en cantidad) \\(\\therefore\\) Tomo 30 artículos, si \\(\\leq 4\\) resultan defectuosos entonces rechazo el lote. 3.2.1 Resumen de Muestreos 3.3 Tipos de Estudios 3.3.0.1 Correlation Analysis (CA) El análisis de correlaciones es muy útil para el investigador para determinar si existe alguna relación o asociación entre diversas variables de interés antes de continuar con un análisis más sofisticado de causa-efecto. El análisis de correlaciones también constituye un insumo fundamental para realizar diversos análisis estadísticos más avanzados como el análisis factorial y el análisis de confiabilidad. Estos análisis son utilizados por los investigadores para determinar la validez y confiabilidad de las encuestas de actitud. 3.3.0.1.1 Statistical assumption of CA El análisis más común es el análisis de correlación de Pearson (Pearson product moment correlacion coefficient). Este tipo de análisis presupone que las variables son ordinales o continuas y que la distribución de estas variables se acerca a la distribución normal (Bell shape curveo “curva de campana”). Es aconsejable que antes de proceder al análisis de correlación de las variables, el investigador estime las estadísticas descriptivas correspondientes para determinar si se cumplen estos supuestos. Estudio observacional: Estudio experimental: Recordar el concepto de efecto placebo, para evitar éste efecto se utilizan grupos control en los estudios. "],
["data-preparation.html", "Capítulo 4 Data Preparation 4.1 Data Transformation", " Capítulo 4 Data Preparation It is important to remember that one of the first steps in data preparation is exploring the distribution of the values in each considered variable. Generally, a normal distribution is prefered over other distributions because there are more tools available to analize data that behaves in a normal way. 4.1 Data Transformation Transactional processes and most metrics that involve time measurements exist with non-normal distributions. Some examples: Mean time to repair HVAC equipment. Admissions cycle time for college applicants. Days sales outstanding. Waiting times at a bank or physicians office. Time being treated in a hospital emergency room. Usted puede transformar los datos usando muchas funciones, tales como raíz cuadrada, logaritmo, potencia, recíproca o arcoseno. La transformación de Box-Cox es fácil de comprender, pero es muy limitada y, con frecuencia, no determina una transformación adecuada. Además, está disponible solo para datos que son positivos. La transformación de Johnson. La función de transformación de Johnson es más complicada, pero es muy efectiva para determinar una transformación adecuada. "],
["data-visualization.html", "Capítulo 5 Data Visualization 5.1 General Concetps 5.2 Análisis Univariante 5.3 Medidas de Tendencia Central 5.4 Medidas de Variabilidad o Dispersión 5.5 Desviación Estándar o Típica 5.6 Propiedades de la Media y Varianza 5.7 Curtosis 5.8 Índice de Asimetría 5.9 Quantile-Quantile Plot (Q-Q plot) 5.10 Boxplots 5.11 Using different graphics in the same exploration 5.12 Other kinds of distributions", " Capítulo 5 Data Visualization 5.1 General Concetps An “outlier” is an extremely high or an extremely low data value when compared with the rest of the data values. Scott’s rule for the bin width w = 3.5σ/ 3√n, where σ is the standard deviation for the entire data set and n is the number of points. This rule assumes that the data follows a Gaussian distribution; otherwise, it is likely to give a bin width that is too wide. Histograms can be either normalized or unnormalized. In an unnormalized histogram, the value plotted for each bin is the absolute count of events in that bin. In a normalized histogram, we divide each count by the total number of points in the data set, so that the value for each bin becomes the fraction of points in that bin. If we want the percentage of points per bin instead, we simply multiply the fraction by 100. 5.1.1 Key points to explore in cuantitative data to begin with: Shape (graphs done with data) Symmetric? Left or right skewed? Unimodal? Bi-modal? Center Mean Median Mode Spread Range (max-min values) IQR (interquartile range): \\(Q_3 - Q_1\\) Outliers 5.2 Análisis Univariante Estudia la distribución individual de cada variable. Este análisis se centra en dos aspectos: La tendencia central de la distribución y su dispersión. En el primer caso hablamos de un valor característico o medio de la distribución, en el segundo de la variabilidad interna de los datos. Según el tipo de variables proceden los siguientes análisis: Variables nominales. Para este tipo de variables el análisis se limita a las frecuencias de cada categoría. Se suele expresar en porcentajes. Variables ordinales. La tendencia central se mide con los estadísticos mediana y moda (pero no la media, ya que ésta implica distancias comparables), mientras que para la dispersión podemos utilizar un diagrama de frecuencias (histograma). Variables métricas. Para el análisis de la tendencia central se utiliza por lo general la media, si bien es aconsejable utilizar la mediana cuando nos encontramos con unos pocos valores extremos cuya magnitud difiere ampliamente del resto (son mucho mayores o mucho menores que la mayoría). Para estudiar el grado de dispersión recurrimos a la desviación típica o la varianza. Es posible estudiar además del momento de primer orden de la distribución (tendencia central) y el momento de segundo orden (dispersión), el momento de tercer orden (simetría) y el de cuarto orden (achatamiento). 5.3 Medidas de Tendencia Central Criterios a seguir: Calcular la media (entre otras razones porque es el mejor estimador del parámetro poblacional). Si no puede calcularse (p.e. variables ordinales, valores extremos) obtener Mediana. Si no puede obtenerse Mediana (p.e. datos nominales, intervalos abiertos con más del 50% de sujetos) obtener Moda. En algunos casos los tres indicadores pueden dar valores similares pero no necesariamente ha de ser así. Mdn = X = Mo, esto solo sucedera sii la distribución es simétrica: 5.4 Medidas de Variabilidad o Dispersión Asimetría positiva. Asimetría negativa. Para conseguir una visión completa y comprensiva de los datos obtenidos hay que complementar las medidas de tendencia central con otros estadísticos que reflejen otras propiedades. Por ejemplo, el grado en que los datos se parecen o diferencian entre sí, propiedad que se denomina variabilidad o variación. 5.4.1 Varianza Es el promedio de las distancias al cuadrado desde los valores en \\(X\\) hasta la media de \\(\\overline X\\) (es decir, de las puntuaciones diferenciales al cuadrado) en una muestra de \\(n\\) sujetos. Fórmulas: \\[S^2_x = \\frac{\\sum(X_i - \\overline X)^2}{N}\\] \\[S^2_x = \\frac{\\sum x^2_i}{N}\\] Fórmula alternativa: \\[S^2_x = \\frac{\\sum X^2_i}{N}-\\overline X^2\\] 5.5 Desviación Estándar o Típica 5.6 Propiedades de la Media y Varianza La media puede tomarse como cualquier valor mientras que \\(S^2X\\) y \\(SX\\) son siempre positivas, siendo su valor mínimo \\(0\\). Si tenemos una misma variable \\(X\\) que ha sido medida en \\(k\\) grupos y conocemos las medidas y varianzas en cada grupo, entonces podemos calcular los estadísticos globalesÑ 5.7 Curtosis Sirve para analizar el grado de concentración que presentan los valores de una variable analizada alrededor de la zona centrla de la distribución de frecuencias, sin necesidad de generar un gráfico. 5.8 Índice de Asimetría La asimetría de una distribución hace referencia al grado en que los datos se reparten por encima y por debajo de la tendencia central. 5.9 Quantile-Quantile Plot (Q-Q plot) It is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a normal or exponential. For example, if we run a statistical analysis that assumes our dependent variable is normally distributed, we can use a Normal Q-Q plot to check that assumption. A Q-Q plot is a scatterplot created by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, we should see the points forming a line that’s roughly straight. 5.9.1 Q-Q plot of a uniform distribution 5.9.2 Q-Q plot of a Poisson distribution 5.9.3 Understanding type of distribution through Q-Q plots 5.10 Boxplots Officially known as box-and-whisker plots, also called boxplots, for short, this is a technique for exploratory data analysis devised by Tukey (1977). One can see the spread and symmetry of a distribution at a glance, and the position of any extreme scores. Hinges: These are the sides of the box in a boxplot, corresponding approximately to the 25th and 75th percentiles of the distribution. H-spread: The distance between the two hinges (i.e., the width of the box) in a boxplot. Inner fences: Locations on either side of the box (in a boxplot) that are 1.5 times the H-spread from each hinge. The distance between the upper and lower inner fence is four times the H-spread. Adjacent values: The upper adjacent value is the highest score in the distribution that is not higher than the upper inner fence, and the lower adjacent value is similarly defined in terms of the lower inner fence of a boxplot. The upper whisker is drawn from the upper hinge to the upper adjacent value, and the lower whisker is drawn from the lower hinge to the lower adjacent value. Outlier: Defined in general as an extreme score standing by itself in a distribution, an outlier is more specifically defined in the context of a boxplot. In terms of a boxplot, an outlier is any score that is beyond the reach of the whiskers on either side. The outliers are indicated as points in the boxplot. Two or more box plots drawn on the same Y-axis. These are often useful in comparing features of distributions. An example portraying the times it took samples of women and men to do a task is shown below. 5.10.1 More elaborate Boxplots Means indicated in green lines rahter than plus signs. Mean of all scores indicated by a gray line. individual scores are represented by dots. Since the scores have been rounded to the nearest second, any given dot might represent more than one score. One box is wider than the other one because the widths of the boxes are proportional to the number of subjects. If all the dots want to be seen we need to add some jitter to the boxplot: 5.11 Using different graphics in the same exploration 5.12 Other kinds of distributions "],
["taller-r.html", "Capítulo 6 Taller R 6.1 ¿Cómo instalar las herramientas? 6.2 ¿Qué es R? 6.3 ¿Cómo obtener ayuda? 6.4 Entrada de datos y su evaluación en la consola 6.5 Estructuras de datos en R 6.6 Utilizando R y RStudio 6.7 ¿Cómo compartir datos y análisis con estadísticos o científicos de datos?", " Capítulo 6 Taller R 6.1 ¿Cómo instalar las herramientas? 6.1.1 Instalando R Las herramientas que utilizaremos será la última versión liberada del software (al momento de hacer éste taller la versión actual es R 3.3.3): Para usuarios Windows. Para usuarios MacOS Para usuarios Linux: Debiant Suse Ubuntu 6.1.2 Instalando RStudio (Integrated Development Environment para R) El utilizar un IDE simplifica considerablemente el trabajo a realizar con R. Instalaciones para: Windows MacOS_X Ubuntu_32Bit Ubuntu_64Bit Fedora 19+/Redhat7+_32Bit Fedora 19+/Redhat7+_64Bit 6.2 ¿Qué es R? 6.2.1 Historia R fué desarrollado a partir de S, un lenguaje desarrollado en Bell Labs por John Chambers y colaboradores. S inicialmente se corría con librerías de Fortran. En 1988 S fué reescrito en C, un lenguaje que también fué desarrollado en Bell Labs. En el libro Statistical Models in S (conocido como el white book) se documentan la funcionalidad para análsis estadísticos a éste nivel de desarrollo de S. La versión 4 de S se liberó en 1998 y se parece mucho a los softwares actuales derivados de S: R y S-PLUS. El libro Programing with Data (conocido como el green book) por John Chambers documenta ésta versión del lenguaje. La filosofía de S: “Queríamos que los usuarios pudieran empezar en un ambiente interactivo, donde ellos no se pensaran, de forma conciente, como programadores. Posteriormente, mientras sus necesidades se hacían más claras y su sofisticación aumentara, podrían”deslizarse&quot; hacia la programación, cuando el lenguaje y el sistema como realizara los procesos se volvieran más importantes para ellos.&quot; (Chambers 2000) R fué desarrollado a partir de S en Nueva Zelanda por Ross Ihaka y Robert Gentleman. Su experiencia en el proceso está documentada en un paper publcado por la Universidad de Auckland, NZ. En 1993 se libera por primera vez al público. En 1997 se forma el R Core Group con gente asociada a S-PLUS. Éste grupo controla el código fuente de R. En 2000 se libera R version 1.0.0 El 7 de Marzo de 2017 se libera R version 3.3.3 6.2.2 Generalidades La sintaxis de R es muy similar a S mas no su semántica. El software es ligero, la funcionalidad del mismo está dada en un formato modular, a través de paquetes. Las capacidades gráficas son sofisticadas y mejores que la mayoría de los paquetes estadísticos. Funciona para realizar actividades de interacción pero también contiene un poderoso lenguaje de programación para el desarrollo de nuevas herramientas (usuario-&gt;programador). La comunidad R es muy activa y dinámica. 6.3 ¿Cómo obtener ayuda? Como se ha comentado en las secciones anteriores, la comunidad R es muy activa, uno de los lugares donde usualmente se obtienen buenas orientaciones es en Stack Overflow. Otro lugar donde se pueden obtener información sobre una función o paquete en específico es en la documentación del paquete que se instala al descargar el mismo. En el siguiente ejemplo se puede ver cómo se explora el comando plot de los paquetes base de R: ?plot Una vez que entiendo cómo trabaja la función plot entonces puedo probar con datos y ver qué obtengo. Ésta es una manera frecuente de resolver dudas o problemas de código. plot(cars) Otro buen lugar para obtener información son las cheat sheets, publicadas por RStudio en su mayoría. Un recurso muy utilizado es la búsqueda en Google. Los cursos en línea han tenido un significativo auge en los últimos años, comparto algunos que considero valen la pena, ésta lista no es exhaustiva: DataCamp DataQuest Udacity Udemy MOOCs: Coursera Edx 6.4 Entrada de datos y su evaluación en la consola Una vez que abrimos la consola R podemos empezar a escribir en el R prompt, los caracteres que se ingresan al R prompt se le llaman expresiones, hay algunas reglas básicas para entrar expresiones: &lt;- es el símbolo que se utiliza como operador de asignación, también es posible utilizar =. #: R interpreta todo lo que esté a la derecha de éste símbolo como un comentario y no lo toma en cuenta para cálculos. Ejemplos: x &lt;- 1 #No se imprime nada, solo se creó un nuevo objeto con un valor numérico. print(x) #impresión explícita ## [1] 1 msg &lt;- &quot;hello&quot; #No se imprime nada, se creó el objeto `msg` con valores `string` o `character` msg #auto-impresión ## [1] &quot;hello&quot; x #auto-imrpesión ## [1] 1 6.5 Estructuras de datos en R 6.5.1 Clases básicas de objetos R tiene 5 clases básicas o atómicas de objetos: Character Valores cualitativos con escalas nominales u ordinales. Numeric (números reales) Números con valores cuantitativos con escalas continuas. Entre un valor y otro hay infinito de otros valores. Integer Números completos, sin fracciones, pueden ser positivos o negativos. Conocidos como valores cuantitativos con escalas discretas. Equidistancia entre un valor y otro. Complex Logical (booleans/binarios/falso-verdadero) Valores con solo dos opciones posibles, ambas mutuamente exclusivas y opuestas. El objeto más básico es el vector: Un vector solo puede contener objetos de la misma clase. La lista permite contener objetos de distintos tipos como un vector. 6.5.2 Atributos Se puede accceder a los atributos de un objeto en R a través de la función attributes(). La información que R entregue será la siguiente: names/dimnames Nombres y/o nombres de dimensiones. dimensions En el caso de matrices y arreglos. class Clase del objeto. length Longitud del objeto. Otros atributos y metadata definidos por el usuario. 6.6 Utilizando R y RStudio En esta sección nos apoyamos con las ilustraciones de Carlos Pérez González y Marcos Colabrook Santamaría (Carlos Pérez-González 2014) 6.6.1 Componentes RStudio Lo primero que haremos es abrir RStudio y explorar los componentes básicos: 6.6.2 Iniciando un proyecto 6.6.2.1 Paso 1 En la esquina superior derecha, identifica el ícono de projecto y da click en él. 6.6.2.2 Paso 2 Puedes elegir crear el proyecto en un directorio que ya exista o crear un directorio nuevo para iniciar. Aún puedes conectar tu projecto a algún administrador de versiones (Git/GitHub). 6.6.2.3 Paso 3 Por ahora la opción empty project es la que utilizaremos. 6.6.2.4 Paso 4 Selecciona el nombre del directorio así como el folder donde se creará en tu ordenador. 6.6.2.5 Paso 5 Al completar los pasos, tu sesión de RStudio debería verse como se muestra en la imagen. 6.6.3 Cargando los datos Hay muchas maneras de cargar datos a R, se puede hacer con líneas de código desde la consola, a través de paquetes preinstalados que ayudan a leer datos en formatos específicos o através de los íconos de RStudio. La siguiente imagen muestra cómo realizar el proceso a través de RStudio: Para éste ejercicio utilizaremos una base de datos que se puede obtener aquí provista amablemente por la compañera Pamela. Si realizamos el ejercicio desde RStuio se producirá el siguiente código con el siguiente resultado. Toma en cuenta que la dirección cambiará dependiendo dónde haz guardado el archivo. library(readr) example &lt;- read_csv(&quot;D:/Dropbox/MsC UABC/2o Semestre/Clases/Estadistica/estadistica-syllabus/datasets/example.csv&quot;) head(example) ## # A tibble: 6 × 17 ## X1 `A&lt;d1&gt;O` EST ENT ENERO FEBRERO MARZO ABRIL MAYO JUNIO ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NA NA NA NA NA NA NA NA NA NA ## 2 NA NA NA NA NA NA NA NA NA NA ## 3 1 1965 4 7 18.83 10.02 36.22 102.36 159.6 149.47 ## 4 2 1966 4 7 22.00 1.00 0.00 98.00 197.0 141.20 ## 5 3 1967 4 7 6.00 40.00 0.00 41.00 137.0 215.00 ## 6 4 1968 2 1 20.40 4.60 45.00 100.00 153.8 165.60 ## # ... with 7 more variables: JULIO &lt;dbl&gt;, AGOSTO &lt;dbl&gt;, SEPTIEMBRE &lt;dbl&gt;, ## # OCTUBRE &lt;dbl&gt;, NOVIEMBRE &lt;int&gt;, DICIEMBRE &lt;int&gt;, VR &lt;int&gt; 6.6.4 Preparando la base de datos De entrada vemos que la base de datos podría “limpiarse” si se eliminaran las filas 1 y 2 así como la columna 1 ya que no aportan información relevante. example &lt;- example[-1:-2,-1] #Estamos creando un subconjunto de `dataset` que se compone de todos los elementos de la base de datos menos las filas 1 y 2 así como la columna 1. colnames(example)[1]&lt;-&quot;Año&quot; #Arregla el problema de caracter en la variable &quot;Año&quot; head(example) ## # A tibble: 6 × 16 ## Año EST ENT ENERO FEBRERO MARZO ABRIL MAYO JUNIO JULIO ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1965 4 7 18.83 10.02 36.22 102.36 159.6 149.47 154.37 ## 2 1966 4 7 22.00 1.00 0.00 98.00 197.0 141.20 158.00 ## 3 1967 4 7 6.00 40.00 0.00 41.00 137.0 215.00 110.00 ## 4 1968 2 1 20.40 4.60 45.00 100.00 153.8 165.60 156.40 ## 5 1969 2 1 5.00 0.00 1.00 222.00 102.0 191.00 124.00 ## 6 1970 2 1 140.00 3.00 105.00 116.00 176.0 302.00 158.00 ## # ... with 6 more variables: AGOSTO &lt;dbl&gt;, SEPTIEMBRE &lt;dbl&gt;, ## # OCTUBRE &lt;dbl&gt;, NOVIEMBRE &lt;int&gt;, DICIEMBRE &lt;int&gt;, VR &lt;int&gt; Con respecto a datos faltantes podemos ver que en la última fila, correspondiente al año 2015, los valores correspondientes al mes de Noviembre y Diciembre están faltantes. Para solucionar éste debemos implementar algún método de imputación de datos para calcular los valores faltantes. El proceso a seguir depende de cada área del conocimiento. 6.6.5 Visualización de datos para análisis exploratorios 6.6.5.1 Buscando tipo de distribución en los datos Para poder evaluar de una manera más cómoda y rápida, vamos a generar histogramas de la distribución de los datos contenidos en todas las variables (columnas) de nuestra base de datos, en éste caso necesitariemos hacer 12 histogramas y compararlos juntos. Utilizaremos el paquete lattice para ésta tarea en específico. Los paquetes se instalan con la funcion install.packages() dentro de los parentesis se pone el nombre del paquete entre comillas. Una vez instalado el paquete se debe llamar a la consola con la función library() y el nombre del paquete dentro de los paréntesis sin comillas. #install.packages(&quot;lattice&quot;) library(lattice) histogram( ~ ENERO +FEBRERO +MARZO +ABRIL +MAYO +JUNIO +JULIO +AGOSTO +SEPTIEMBRE +OCTUBRE +NOVIEMBRE +DICIEMBRE, data = example, main = &#39;Histogramas para Evaluación Inicial de Distribución de los Datos&#39;) Ésta información se puede obtener también con la función summary(): summary(example) ## Año EST ENT ENERO ## Min. :1965 Min. :1.000 Min. :1.000 Min. : 0.0 ## 1st Qu.:1978 1st Qu.:1.000 1st Qu.:1.000 1st Qu.: 0.0 ## Median :1990 Median :1.000 Median :1.000 Median : 7.0 ## Mean :1990 Mean :1.549 Mean :1.353 Mean : 18.4 ## 3rd Qu.:2002 3rd Qu.:2.000 3rd Qu.:1.000 3rd Qu.: 21.2 ## Max. :2015 Max. :4.000 Max. :7.000 Max. :140.0 ## ## FEBRERO MARZO ABRIL MAYO ## Min. : 0.0 Min. : 0.00 Min. : 0.0 Min. : 55.0 ## 1st Qu.: 0.0 1st Qu.: 0.00 1st Qu.: 50.0 1st Qu.:136.5 ## Median : 2.0 Median : 28.80 Median : 88.0 Median :167.0 ## Mean : 10.5 Mean : 36.46 Mean :107.5 Mean :169.8 ## 3rd Qu.: 12.5 3rd Qu.: 51.00 3rd Qu.:139.0 3rd Qu.:197.5 ## Max. :113.0 Max. :132.00 Max. :465.0 Max. :367.0 ## ## JUNIO JULIO AGOSTO SEPTIEMBRE ## Min. : 16.0 Min. : 60.0 Min. : 39.0 Min. : 30.1 ## 1st Qu.:111.0 1st Qu.:110.0 1st Qu.:141.5 1st Qu.:123.0 ## Median :143.0 Median :156.4 Median :171.0 Median :166.5 ## Mean :155.7 Mean :162.8 Mean :179.1 Mean :171.3 ## 3rd Qu.:189.5 3rd Qu.:198.1 3rd Qu.:212.0 3rd Qu.:217.0 ## Max. :388.0 Max. :311.0 Max. :402.0 Max. :455.0 ## ## OCTUBRE NOVIEMBRE DICIEMBRE VR ## Min. : 32.0 Min. : 0.00 Min. : 0.00 Min. : 396 ## 1st Qu.:104.5 1st Qu.: 66.75 1st Qu.: 12.50 1st Qu.:1145 ## Median :132.8 Median :105.50 Median : 29.00 Median :1297 ## Mean :152.2 Mean :117.68 Mean : 46.28 Mean :1295 ## 3rd Qu.:185.0 3rd Qu.:155.75 3rd Qu.: 64.75 3rd Qu.:1466 ## Max. :289.0 Max. :374.00 Max. :208.00 Max. :1957 ## NA&#39;s :1 NA&#39;s :1 De los resultados generados por summary() se pueden obtener la siguiente información de cada variable: Media Mediana Rango Intercuartil Valor mínimo Valor máximo 6.6.5.2 Medidas de tendencia central Seleccionaremos los meses de Abril y Agosto para calcular medidas de tendencia central, de los histogramas previos podemos intuir que uno de éstos meses tiene un “comportamiento normal” y el otro no. Para éste ejercicio utilizarmos el generador de gráficas que viene con los paquetes báiscos cuando se instala R. 6.6.5.2.1 Distribuciones no Normales Gráfica Base hist(example$ABRIL, #Histograma base col = &quot;darksalmon&quot;, #color del relleno de las barras border = &quot;black&quot;, #color del borde de las barras prob = TRUE, #le indica a R que los histogramas se realizaran en base a densidad y no a cantidad. xlab = &quot;Milímetros de Agua&quot;, ylab = &quot;Frecuencia&quot;, main = &quot;Precipitación durante el mes de Abril de los años 1965 a 2015&quot;) Para una lista de los colores que puedes utilizar con las gráficas base de R puedes consultar aquí. Medidas de Tendencia Central Una vez que la gráfica base está desarrollada, procederemos a agregar la curva de distribución, las líneas de media y mediana. hist(example$ABRIL, #Histograma base col = &quot;darksalmon&quot;, #color del relleno de las barras border = &quot;black&quot;, #color del borde de las barras prob = TRUE, #le indica a R que los histogramas se realizaran en base a densidad y no a cantidad. xlab = &quot;Milímetros de Agua&quot;, ylab = &quot;Frecuencia&quot;, main = &quot;Precipitación durante el mes de Abril de los años 1965 a 2015&quot;) ##Distribución## lines(density(example$ABRIL), #Línea base de distribución lwd = 3, #ancho de la linea col = &quot;deeppink&quot; #color of line ) ##Media## abline(v = mean(example$ABRIL), #Línea base lwd = 2, #Ancho de línea col = &quot;blue&quot; #Color de línea ) ##Mediana## abline(v = median(example$ABRIL), ##Línea básica lwd = 2, col = &quot;chartreuse&quot;) Leyenda hist(example$ABRIL, #Histograma base col = &quot;darksalmon&quot;, #color del relleno de las barras border = &quot;black&quot;, #color del borde de las barras prob = TRUE, #le indica a R que los histogramas se realizaran en base a densidad y no a cantidad. xlab = &quot;Milímetros de Agua&quot;, ylab = &quot;Frecuencia&quot;, main = &quot;Precipitación durante el mes de Abril de los años 1965 a 2015&quot;) ##Distribución## lines(density(example$ABRIL), #Línea base de distribución lwd = 3, #ancho de la linea col = &quot;deeppink&quot; #color of line ) ##Media## abline(v = mean(example$ABRIL), #Línea base lwd = 2, #Ancho de línea col = &quot;blue&quot; #Color de línea ) ##Mediana## abline(v = median(example$ABRIL), ##Línea básica lwd = 2, col = &quot;chartreuse&quot;) ##Leyenda legend(x = &quot;topright&quot;, #Dónde se va a ubicar la leyenda con relación a la gráfica c(&quot;Gráfica de Densidad&quot;, &quot;Media&quot;, &quot;Mediana&quot;), lwd = c(3,2,2), col = c(&quot;deeppink&quot;, &quot;blue&quot;, &quot;chartreuse&quot;)) 6.6.5.3 Distribuciones Normales AGOSTO Realiza el mismo proceso para obtener una gráfica del mes de AGOSTO como la que se presenta abajo: 6.7 ¿Cómo compartir datos y análisis con estadísticos o científicos de datos? Una breve guía de cómo compartir datos con personas que se dedican a la estadística o ciencia de datos (Leek 2016), Jeff Leek dice que los datos compartidos deben venir ordenados en cuatro grandes grupos/folders/repositorios: Datos crudos. Datos que no han sido manipulados por ningún software de minería de datos o algún otro. Una base de datos “arreglada” (tidy dataset). Cada fila una instancia/paciente/ente a medir. Cada columna una variable. Cada celda un valor de la variable correspondiente. Un libro de códigos que explique cada variable y sus valores en en la base de datos “arreglada”. Una receta explícita y exacta de lo que se hizo para ir de 1 –&gt; 2,3, étc References "],
["tareas.html", "Capítulo 7 Tareas 7.1 Point Chart 7.2 Stratified Sampling", " Capítulo 7 Tareas 7.1 Point Chart 7.2 Stratified Sampling author: Dolores Ojeda, Gener Avilés R date: 2017-03-05 7.2.1 What is Stratified Sampling? Population is partitioned in non-overlaping groups, called strata and a sample is collected from each stratum following a determined design. 7.2.2 Why use Stratified Sampling? - May produce smaller error when estimating than simple random sample. Specially when measurements within strata have realitve small variation. - Cost by observation reduced. - There may be a need to have a subgroup (stratum) with similar estimates of those of the population. 7.2.3 Example The Titanic Database: ## &lt;U+FEFF&gt;pclass survived name sex ## Min. :1.000 Min. :0.000 Length:1310 Length:1310 ## 1st Qu.:2.000 1st Qu.:0.000 Class :character Class :character ## Median :3.000 Median :0.000 Mode :character Mode :character ## Mean :2.295 Mean :0.382 ## 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :1.000 ## NA&#39;s :1 NA&#39;s :1 ## age sibsp parch ticket ## Min. : 0.1667 Min. :0.0000 Min. :0.000 Length:1310 ## 1st Qu.:21.0000 1st Qu.:0.0000 1st Qu.:0.000 Class :character ## Median :28.0000 Median :0.0000 Median :0.000 Mode :character ## Mean :29.8811 Mean :0.4989 Mean :0.385 ## 3rd Qu.:39.0000 3rd Qu.:1.0000 3rd Qu.:0.000 ## Max. :80.0000 Max. :8.0000 Max. :9.000 ## NA&#39;s :264 NA&#39;s :1 NA&#39;s :1 ## fare cabin embarked ## Min. : 0.000 Length:1310 Length:1310 ## 1st Qu.: 7.896 Class :character Class :character ## Median : 14.454 Mode :character Mode :character ## Mean : 33.295 ## 3rd Qu.: 31.275 ## Max. :512.329 ## NA&#39;s :2 ## boat body home.dest ## Length:1310 Min. : 1.0 Length:1310 ## Class :character 1st Qu.: 72.0 Class :character ## Mode :character Median :155.0 Mode :character ## Mean :160.8 ## 3rd Qu.:256.0 ## Max. :328.0 ## NA&#39;s :1189 7.2.3.1 Variable Codes - Pclass: 1 = Upper, 2 = Middle, 3 = Lower. - SibSp: Number of Siblings/Spouses aboard. - Parch: Number of Parents/Children Aboard. - Embarked: C = Cherbourg, Q = Queenstown, S = Southampton. 7.2.3.2 Calculating Probabilities to select people who embarked in Queenstown \\(P(A) = \\frac{\\text{Numero de elementos de A}}{n}\\) There are 1310 entries, and 123 of them embarked in Queenstown, nevertheless the risk of dying was equally present for them as for the passengers from Southampton or Cherbourg. If a uniform proability is calculated the numbers are: - \\(P(Q) = \\frac{123}{1310} =\\) 0.0938931 - \\(P(C) = \\frac{270}{1310} =\\) 0.2061069 - \\(P(S)\\frac{914}{1310} =\\) 0.6977099 This approximation will hinder the process of data mining and, eventually, the generation of a machine learning model for survival prediction. 7.2.3.3 Fixing the Problem By using stratified sampling we can raise the probability for the group that boarded in Queenstown and survived to be selected, therefore, taken in consideration for the generation of a survival prediction model. For this we will use conditional probability: \\(P(Survived|EmbarkedQ)= \\frac{P(Survived\\cap EmbarkedQ)}{P(EmbarkedQ)} = \\frac{44}{123}=\\) 0.3577236 library(dplyr) Q&lt;-filter(titanic, embarked == &quot;Q&quot; &amp; survived == 1) count(Q) ## # A tibble: 1 × 1 ## n ## &lt;int&gt; ## 1 44 "]
]
