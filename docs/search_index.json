[
["index.html", "Estadística para el Análisis de Datos Capítulo 1 Introducción", " Estadística para el Análisis de Datos Gener Avilés R 2017-03-08 Capítulo 1 Introducción Curso impartido por: Dr. Juan Iván Nieto Hipólito Dra. María de los Ángeles Cosío León "],
["conceptos-generales.html", "Capítulo 2 Conceptos Generales 2.1 Terms comparing statistics and computer sciences 2.2 Teoria de Conjuntos 2.3 Diagramas de Venn 2.4 Algebra de Conjuntos 2.5 Leyes de Morgan 2.6 Modelos De Probabilidad 2.7 Probabilidad Condicional", " Capítulo 2 Conceptos Generales 7 de Febrero 2017 Cuando se tiene un modelo conocido que se asemeja al conjunto de datos, se le llama modelo parametrico. P.ej: \\[\\int_{a}^{b} f(x)dx\\] La robustez del modelo la da el coeficiente de correlacion (\\(R^2\\)), el cual nos habla de que tanto se parece el modelo a los datos. los valores van de \\(0-1\\), un valor \\(&gt;0.9\\) se considera adecuado. Cunado los datos no se parecen a un modelo ya conocido, se utilizan los modelos no parametricos. 2.1 Terms comparing statistics and computer sciences 2.2 Teoria de Conjuntos 2.2.1 Definiciones Conjunto: Una coleccion de elementos con caracteristicas que comparten entre ellos. \\[A=\\text{{1,2,3,4}}\\] \\[B = \\text{{numeros enteros positivos}}\\] \\[ C = \\text{{numeros enteros &gt; 3}} = \\text{{4,5,6...}}\\] Todos estos tipos de conjuntos se pueden convertir eventualmente en el espacio muestral, por lo tanto la definicion del espacio muestral es vital antes de iniciar procesos de anlalisis. Alternativamente, los elementos \\(x\\) de un conjunto se pueden enunciar de tal manera que cumplan una caracteristica \\(P\\). \\[\\text{{x|x satisface P}}\\] En esta notacion, el simbolo \\(|\\) se interpreta como: “tal que”. Otro ejemplo con esta notacion: \\[ E = \\{x|x \\space numero\\space entero\\space 4 \\leq x \\leq 10\\}\\] Pertenece a (\\(\\in\\)): Tomando el ejemplo anterior, podemos decir que \\(x = 5 \\in E\\). No pertenece a (\\(\\notin\\)) Tomando el ejemplo anterior podemos decir que \\(x = 11 \\notin E\\) Subconjunto (\\(\\subset\\)) Cuando todos los elementos del conjunto \\(A\\) estan incluidos en el conjunto \\(B\\) (\\(A \\subset B\\)) Complemento (\\(^c\\)) El complemento de un conjunto \\(S\\), con respecto al conjunto universo (\\(\\Omega\\)), otros autores utilizan \\(U\\), es el conjunto de todos los elementos que no pertenecen a \\(S\\), y se denota como \\(S^c\\). Es importante recordar que \\(\\Omega^c = \\emptyset\\) donde \\(\\emptyset\\) es el conjunto vacio. Union (\\(\\cup\\)) \\[S \\cup T = \\{x|x \\in or\\space x\\in T\\}\\] Intereseccion (\\(\\cap\\)) \\[S \\cap T = \\{x|x \\in S\\space y \\space x \\in T \\} \\] Por lo tanto: \\[\\bigcup_{n=1}^{\\infty}= S_1 \\cup S_2 \\cup ...= \\{ x|x \\in S_n para \\space alguna\\space n\\} \\] Donde \\(para\\space S_n = \\space un \\space entero \\space positivo\\). \\[ \\bigcap_{n=1}^{\\infty} = S_1 \\cap S_2 \\cap ... = \\{ x|x \\in S_n \\space para \\space alguna \\space n\\}\\] 2.2.2 Conjuntos Disjuntos Son aquellos cuya interseccion (\\(\\cap\\)) es el conjunto vacio (\\(\\emptyset\\)). No se intersectan. \\[S \\cap T = \\{ \\emptyset\\}\\] La probabilidad del conjunto vacio no es igual a \\(\\emptyset\\), por lo tanto habra que calcularla en cada caso. 2.2.3 Partición: Una colección de conjuntos se dice que es una particion de un conjunto \\(S\\) si los conjuntos en la coleccion son disjuntos y su union es \\(S\\). \\[S = \\{1,2,3,4,5,6,7,8\\}\\] \\(A = \\{1,2,3\\}\\), \\(B = \\{4,5,6,7,8\\}\\) y \\(C = \\{\\emptyset\\}\\) Ojo: simpre considerar la probabilidad del conjunto vacio, siempre existe. Si \\(x\\) y \\(y\\) son 2 objetos \\((x,y)\\) para describir un par ordenado, por ejemplo, numeros reales \\(R\\), el conjunto de pares (o tripleta) de escalares se puede escribir como \\(R^2\\) y \\(R^3\\), respectivamente. 2.3 Diagramas de Venn \\(A \\cap B\\) \\(A\\cup B\\) \\(A^c \\cap B\\) \\(\\text{Conjuntos Disjuntos}\\) \\(S,T,\\space y \\space V \\space son \\space una \\space particion \\space de \\space \\Omega\\) 2.4 Algebra de Conjuntos Propiedad asociativa ???? \\[S \\cup T = T \\cup S\\] \\[S \\cap (T \\cup V) = (S \\cap T) \\cup (S \\cap V)\\] \\[(S^c)^c = S\\] \\[S \\cup \\Omega = \\Omega\\] Propiedad Distributiva???? \\[S \\cup (T \\cup V) = (S \\cup T)\\cup V\\] \\[S \\cup (T \\cap V) = (S \\cup T)\\cap (S \\cap V)\\] \\[S \\cap S^c = \\emptyset\\] \\[S \\cap \\Omega = S\\] 2.5 Leyes de Morgan Considerar las siguentes notaciones: \\((\\bigcup_{n}^{}S_n)^c = \\bigcap_{n}^{}{S_n}^c\\) \\((\\bigcap S_n)^2 = \\bigcup_{n}^{}{S_n}^c\\) *Notar como cambian de \\(\\cup\\) a \\(\\cap\\) y viceversa, en estas leyes. 8 de Febrero de 2017 2.6 Modelos De Probabilidad Buscan proveer certidumbre o reducir incertidumbre. 2.6.1 Elementos de un Modelo de Probabilidad El espacio muestral (\\(\\Omega\\)): Entendido como el conjunto de todos los posibles resultados de un experimento. Ley de probabilidad, la cual asigna a un conjunto \\(A\\) de posibles resultados (llamdo también evento) un número no-negativo (\\(P(A) = (\\text{la probabilidad de A})\\)) que codifica nuestro conocimiento o creencia sobre la probabilidad de los elementos de \\(A\\). 2.6.2 Axiomas de Probabilidad No negatividad Para cada uno de los eventos en \\(A\\): \\(P(A) \\geq 0\\) Adición Si \\(A\\) y \\(B\\) son dos eventos disjuntos, entonces la posibilidad de su unión satisface: \\(P(A \\cup B) = P(A)+P(B)\\) ó \\(P(A_1\\cup A_2 \\cup ...A_n) = P(A_1) + P(A_2)+...P(A_n)\\) Normalización La probabilidad del copmleto (entire) espacio muestral \\(\\Omega\\) es \\(1\\), esto es \\(P(\\Omega) = 1\\). Ojo: Los eventos del espacio muestral deben ser eventos mutuamente excluyentes, osea que no puedan suceder simultaneamente. 2.6.3 Ley de Probabilidad Discreta Probabilidad discreta: Asignar a un evento una probabilidad única (valor). Si el espacio de probabilidad consiste de un número finito de posibles resultados, entonces la ley de probabilidad se especifica por las probabilidades de cada uno de los eventos. En particular, la probabilidad de cualquier evento. \\(\\{S_1,S_2,...S_n\\}\\) es la suma de las probabilidades de sus elementos: \\[P(\\{S_1,S_2,...S_n\\}) = P(S_1)+P(S_2)+...+P(S_n)\\] 2.6.4 Ley de Probabilidad Discreta Uniforme Si el espacio muestral consiste de \\(n\\) posibles resultados con igual probabilidad de ocurrencia, entonces la probabilidad de cualquier evneto \\(A\\), está dada por: \\[P(A)= \\frac{\\text{Número de elementos de A}}{n}\\] 2.6.5 Función Densidad de Probabilidad También conocida como Probability Density Function (pdf) o Probability Mass Function (pmf). Para una variable aleatoria o evento discreto, se define como: \\[f(x) = P(X=x)\\] 2.6.6 Acumulativa pdf (Comulative pdf) Se define como la suma de los resultados parcials de los eventos que validan el experimento: \\[cpdf = \\sum_{i}(P(x_i=x))\\] Para los \\(x_i\\) que validan el experimento. 14 de Febrero 2017 2.7 Probabilidad Condicional La siguiente ecuación: \\[P(A/B) = \\frac{P(A\\cap B)}{P(B)}\\] Puede también ser expresada en los términos de probabilidad condicional secuencial: \\[P(A\\cap B) = P(A/B)*P(B)\\] Siempre y cuando \\(P(B)&gt;0\\) Si los posibles resultados tienen la misma probabilidad de ocurrencia entonces: \\[P(A/B) = \\frac{\\text{No. de elementos en } A\\cap B}{\\text{No. de elementos en }B}\\] Importante: El conjunto universo en la probabilidad condicional (dado un evento anterior) cambia de \\(\\Omega\\) al subconjunto \\(B\\). 2.7.0.1 Ejemplos: Considerar el lanzamiento de 2 dados: \\[A = \\{\\text{la suma es}\\geq 8 \\space y \\space \\leq 10\\}\\] \\[B = \\{\\text{el dado 1}=6 \\} \\therefore P(B) = \\frac {1}{6}\\] Recordando los conceptos de combinaciones: \\(C = n^m\\) cuando \\(n\\) es el número de posibles resultados y \\(m\\), el número de experimentos. para éste ejemplo en particular las combinaciones posibles son \\(6^2 = 36\\), entonces: \\[P(A\\cap B) = \\frac {3}{36} \\therefore P(A/B) = \\frac {\\frac {3}{36}}{\\frac {1}{6}} = \\frac {18}{36} = \\frac {1}{2}\\] Es importante que la probabilidad condicional es mayor a la probabilidad independiente de previos eventos, porque el universo en la condicional disminuye de \\(\\Omega\\) a un subconjunto, en éste caso \\(B\\). La probabilidad de que, al lanzar los dados del ejemplo anterior, la suma sea \\(\\geq 8\\) y \\(\\leq 10\\) ó \\(A = \\{\\geq 8 \\space y \\space \\leq 10\\}.\\) A ésta probabilidad la denotaremos como \\(P(A)\\), al realizar el experimento manual obtenemos la siguiente imagen: Se puede observar que se han indicado las combinaciones que cumplen con una suma \\(\\geq 8\\) y \\(\\leq 10\\) ó \\(A = \\{\\geq 8 \\space y \\space \\leq 10\\}\\). Por lo tanto: \\[P(A) = \\frac {12}{36} = \\frac {1}{3}\\]. Otra manera de entender éste concepto es visualizarlo a través de una matriz: Con la visualización, es sencillo llegar a la conclusión \\(A = \\frac {12}{36} = \\frac {1}{3}\\) En el lanzamiento sucesivo de 3 monedas, queremos saber la probabilidad condicional, \\(P(A/B)\\), cuando \\(A\\) y \\(B\\) son los eventos: \\[A = \\{\\text{aparecen más soles que águilas}\\}\\] \\[B = \\{\\text{el primer lanzamiento cae sol}\\}\\] La visualización de todas las posibilidades de éste fenómeno se puede apreciar en la siguiente figura: Derivado del árbol en la imagen se pueden determinar las probabilidades de los siguientes subconjuntos: \\[P(A) = \\{\\text{sss, ssa, sas, ass }\\} = \\frac {4}{8} = \\frac {1}{2}\\] \\[P(B) = \\{\\text{sss, ssa, sas, saa}\\} = \\frac{4}{8} = \\frac{1}{2}\\] \\[P(A\\cap B) = \\{\\text{sss, ssa, sas}\\} = \\frac{3}{8}\\] \\[\\therefore\\] \\[P(A/B) = \\frac {P(A\\cap B)}{P(B)} = \\frac {\\frac {3}{8}}{\\frac {1}{2}} = \\frac {6}{8} = \\frac {3}{4}\\] Nótese el la mayor probabilidad de \\(P(A/B)\\) dado que el universo pasó de ser \\(\\Omega\\) al subconjunto \\(B\\). 2.7.1 Repaso de combinaciones y permutaciones La cantidad total de combinaciones posibles en un experimento se puede calcular como \\(n^m\\) donde: \\[n = \\text{posibles resutlados}\\] \\[m = \\text{número de experimentos a realizar}\\] Cuando de un número de combinaciones se elige una muestra \\(r\\) y el orden en el que éstas se elige no importa (combinaciones): \\[P = \\left( \\begin{array}{c} n \\\\ r \\end{array} \\right) = \\frac {n!}{r!(n-r)!}\\] Cuando de un numero de combinaciones se elige una muestra \\(r\\) y el orden en el que ésta se elige SI importa (permutaciones): \\[P = \\left( \\begin{array}{c} n \\\\ r \\end{array} \\right) = \\frac {n!}{(n-r)!}\\] 2.7.1.1 Ejemplo: Al lanzar 8 dados, ¿cuántas combinaciones diferentes son posibles? \\[C = 6^8\\] PENDIENTE REVISAR- Si elijo el resultado de 2 dados de los 8 lanzados, ¿de cuántas maneras distintas los puedo elegir?: \\[P = \\left( \\begin{array}{c} 8 \\\\ 2 \\end{array} \\right) = \\frac {n!}{r!(n-r)!}\\] Siempre y cuando \\(A_1\\) y \\(A_2\\) sean eventos disjuntos (\\(P(A_1\\cap A_2) = \\emptyset\\)) podemos entonces decir que: \\[P = (A_1 \\cap A_2 \\vert B) = \\frac {P(A_1 \\cap B)}{P(B)}+ \\frac {P(A_2 \\cap B)}{P(B)} = P(A_1/B) + P(A_2/B)\\] 2.7.1.2 Ejemplo Tomando datos del experimento anterior con monedas: \\[A_1 = \\{\\text{aparecen más soles que águilas}\\} = \\{\\text{sss, ssa, sas, ass}\\}\\] \\[A_2 = \\{\\text{aparecen más águilas que soles}\\} = \\{\\text{ssa, asa, aas, aaa}\\}\\] \\[B = \\{\\text{el primer lanzamiento es sol}\\} = \\{\\text{sss, ssa, sas, saa}\\}\\] \\[A_1 \\cap A_2 = \\{\\emptyset\\}\\] \\[\\therefore\\] \\[P(A_1) = \\frac {4}{8} = \\frac {1}{4}\\space \\&amp; \\space P(A_2) = \\frac {4}{8} = \\frac {1}{4}\\] \\[P(A_1\\cap B) = \\frac{3}{8}\\] \\[P(A_2\\cap B) = \\frac{1}{8}\\] \\[P(A_1\\cup A_2\\vert B) = \\frac {\\frac{3}{8}}{\\frac{1}{2}} + \\frac{\\frac{1}{8}}{\\frac{1}{2}} = \\frac{6}{8} + \\frac{2}{8} = 1\\] \\[P(A_1\\cup A_2\\vert B) = 1 \\space \\therefore\\] \\[P(A_1\\cup A_2...\\cup A_i \\vert B) = P(A_1/B) + P(A_2/B)+...+ P(A_i/B)\\] Siempre y cuando \\(\\{A_1\\cap A_2...\\cap A_i\\}= \\emptyset\\). 2.7.2 Independencia Si: \\[P(A\\cap B) = P(A)*P(B)\\] Se dice que \\(A\\) y \\(B\\) son eventos independientes. Distinto a ser eventos disjuntos: \\(P(A\\cap B) = \\emptyset\\). Entonces, asumiendo independencia obetnemos: \\[P(A/B) = \\frac {P(A\\cap B)}{P(B)} = \\frac{P(A)P(B)}{P(B)} = P(A)\\] La ecuación anterior demuestra que, los eventos independientes no afectan la probabilidad uno del otro. "],
["recoleccion-de-datos.html", "Capítulo 3 Recolección de Datos 3.1 Definiciones 3.2 Tipos de Muestreo 3.3 Tipos de Estudios", " Capítulo 3 Recolección de Datos 3.1 Definiciones A primary goal of statistical studies is to collect data that can then be used to make informed decisions. It should come as no surprise that the ability to make good decisions depends on the quality of the information available. Datos: colección de información sobre las variables de interés. Para poder tener una colección habrá que definir la población de donde saldrán éstos datos: Población: Conjunto de datos, objetos, humanos, experiencias, étc. Población infinita: Aquella que no se puede o es difícil de contar. (población difícil o no contable) Población finita: se puede contar y/o medir. Población muestreada: subconjunto de la población que reúne todas las características (parámetros) de la población. Parámetro: unidad de medida de los atributos, características de la población. Muestra: Subconjunto de la población. Estadísticos: unidad de medida de un atributo o característica de la muestra. Censo: cuando la población se analiza en su totalidad. A study is an observational study if the investigator observes characteristics of a sample selected from one or more existing populations. The goal of an observational study is usually to draw conclusions about the corresponding population or about differences between two or more populations. In a well-designed observational study, the sample is selected in a way that is designed to produce a sample that is representative of the population. A study is an experiment if the investigator observes how a response variable behaves when one or more explanatory variables, also called factors, are manipulated. The usual goal of an experiment is to determine the effect of the manipulated explanatory variables (factors) on the response variable. In a well-designed experiment, the composition of the groups that will be exposed to different experimental conditions is determined by random assignment. 3.2 Tipos de Muestreo Advantages of sampling methods: Reduced cost. Greater speed. Greater Scope Greater Accuracy 3.2.0.1 Types of sampling 3.2.0.1.1 Non Probabilistic Techniques Muestreo por Conveniencia: Los encuestados son seleccionados porque estaban en el lugar preciso en el momento adecuado. Muestreo por Juicio: Los encuestados son seleccionados siguiendo el criterio del investigador, basándose en su conocimiento de la población objetivo. Muestreo Encadenado: Se selecciona a una muestra que sirve como punto de partida para otra muestra. Se utiliza cuando, por la naturaleza delicada de la pregunta o la dificultad de encontrar a los encuestados, es necesario que el encuestado nos dirija a otro. Un ejemplo típico de la utilidad de este método sería la investigación sobre hábitos de conducta moralmente no aceptados por la sociedad. Muestreo por Cuotas: En este caso el investigador tiene una información más detallada de la distribución de la población según algunas variables que están relacionadas con la variable a estudiar. De acuerdo con estas variables se divide la población en estratos y se entrevista un número determinado en cada estrato. 3.2.0.1.2 Probabilistic Techniques Muestreo Aleatorio Simple (MAS): Cada elemento de la población y cada posible muestra de un tamaño n tienen una probabilidad conocida e igual de ser seleccionados. Esta técnica requiere tener un listado exhaustivo de todos los elementos de la población objetivo. Errores que arruinan el muestreo aleatorio simple (buscar evitarlos siempre): Tendencias. Prejuicios. Parcialidades. Muestreo Sistemático: Se elige un primer elemento aleatoriamente y a continuación todos los siguientes cada n posiciones. Así, si por ejemplo queremos seleccionar 20 individuos de entre 100, el primer paso es seleccionar un número aleatorio entre 1 y 5 (ya que 100/20=5), digamos el 3; a continuación seleccionamos los individuos 3, 8, 13, 18,… 93, 98. Esto implica la ordenación de todos los elementos de la población, si bien el criterio de ordenación no debe guardar ninguna relación con el fenómeno sociológico a estudiar. Muestreo Estratificado: Requiere al menos dos etapas. En una primera etapa la población objetivo se divide en estratos según las variables que se consideran relacionadas con el fenómeno sociológico a estudiar. La segunda fase consiste en seleccionar aleatoriamente una muestra dentro de cada estrato. Muestreo por conglomerados (clusters): Monoetápico: La población es dividida en conglomerados (barrios, manzanas), seleccionando un grupo de ellos con probabilidad proporcional a su importancia. Una vez se tienen estos conglomerados se encuesta a todos los elementos del conglomerado (todos los vecinos de las manzanas B, H y G). Bietápico: Igual que el anterior pero en lugar de encuestar a todos los elementos del conglomerado se selecciona una muestra. 1-in-\\(k\\) systematic sampling/ muestreo sistemático 1-en-\\(k\\): Consiste en seleccionar cada \\(k\\)-ésima unidad. Útil para muestreo de artículos en líneas de producción. Ejemplos: Muestreo con reemplazo: En un lote de 1000 artículos. Agarro 20 al hazar, si \\(\\leq 4\\) están defectuosos, acepto el lote. Muestreo sin remplazo: Después de sacar 20, vuelvo a muestrear a los 980 restantes (con ésta técnica la muestra aumenta, dado que \\(\\Omega\\) disminuye y la cantidad de artículos defectuosos siguen siendo los mismos en cantidad) \\(\\therefore\\) Tomo 30 artículos, si \\(\\leq 4\\) resultan defectuosos entonces rechazo el lote. 3.2.1 Resumen de Muestreos 3.3 Tipos de Estudios 3.3.0.1 Correlation Analysis (CA) El análisis de correlaciones es muy útil para el investigador para determinar si existe alguna relación o asociación entre diversas variables de interés antes de continuar con un análisis más sofisticado de causa-efecto. El análisis de correlaciones también constituye un insumo fundamental para realizar diversos análisis estadísticos más avanzados como el análisis factorial y el análisis de confiabilidad. Estos análisis son utilizados por los investigadores para determinar la validez y confiabilidad de las encuestas de actitud. 3.3.0.1.1 Statistical assumption of CA El análisis más común es el análisis de correlación de Pearson (Pearson product moment correlacion coefficient). Este tipo de análisis presupone que las variables son ordinales o continuas y que la distribución de estas variables se acerca a la distribución normal (Bell shape curveo “curva de campana”). Es aconsejable que antes de proceder al análisis de correlación de las variables, el investigador estime las estadísticas descriptivas correspondientes para determinar si se cumplen estos supuestos. Estudio observacional: Estudio experimental: Recordar el concepto de efecto placebo, para evitar éste efecto se utilizan grupos control en los estudios. "],
["tareas.html", "Capítulo 4 Tareas 4.1 Point Chart 4.2 Stratified Sampling", " Capítulo 4 Tareas 4.1 Point Chart 4.2 Stratified Sampling author: Dolores Ojeda, Gener Avilés R date: 2017-03-05 4.2.1 What is Stratified Sampling? Population is partitioned in non-overlaping groups, called strata and a sample is collected from each stratum following a determined design. 4.2.2 Why use Stratified Sampling? - May produce smaller error when estimating than simple random sample. Specially when measurements within strata have realitve small variation. - Cost by observation reduced. - There may be a need to have a subgroup (stratum) with similar estimates of those of the population. 4.2.3 Example The Titanic Database: ## &lt;U+FEFF&gt;pclass survived name sex ## Min. :1.000 Min. :0.000 Length:1310 Length:1310 ## 1st Qu.:2.000 1st Qu.:0.000 Class :character Class :character ## Median :3.000 Median :0.000 Mode :character Mode :character ## Mean :2.295 Mean :0.382 ## 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :1.000 ## NA&#39;s :1 NA&#39;s :1 ## age sibsp parch ticket ## Min. : 0.1667 Min. :0.0000 Min. :0.000 Length:1310 ## 1st Qu.:21.0000 1st Qu.:0.0000 1st Qu.:0.000 Class :character ## Median :28.0000 Median :0.0000 Median :0.000 Mode :character ## Mean :29.8811 Mean :0.4989 Mean :0.385 ## 3rd Qu.:39.0000 3rd Qu.:1.0000 3rd Qu.:0.000 ## Max. :80.0000 Max. :8.0000 Max. :9.000 ## NA&#39;s :264 NA&#39;s :1 NA&#39;s :1 ## fare cabin embarked ## Min. : 0.000 Length:1310 Length:1310 ## 1st Qu.: 7.896 Class :character Class :character ## Median : 14.454 Mode :character Mode :character ## Mean : 33.295 ## 3rd Qu.: 31.275 ## Max. :512.329 ## NA&#39;s :2 ## boat body home.dest ## Length:1310 Min. : 1.0 Length:1310 ## Class :character 1st Qu.: 72.0 Class :character ## Mode :character Median :155.0 Mode :character ## Mean :160.8 ## 3rd Qu.:256.0 ## Max. :328.0 ## NA&#39;s :1189 4.2.3.1 Variable Codes - Pclass: 1 = Upper, 2 = Middle, 3 = Lower. - SibSp: Number of Siblings/Spouses aboard. - Parch: Number of Parents/Children Aboard. - Embarked: C = Cherbourg, Q = Queenstown, S = Southampton. 4.2.3.2 Calculating Probabilities to select people who embarked in Queenstown \\(P(A) = \\frac{\\text{Numero de elementos de A}}{n}\\) There are 1310 entries, and 123 of them embarked in Queenstown, nevertheless the risk of dying was equally present for them as for the passengers from Southampton or Cherbourg. If a uniform proability is calculated the numbers are: - \\(P(Q) = \\frac{123}{1310} =\\) 0.0938931 - \\(P(C) = \\frac{270}{1310} =\\) 0.2061069 - \\(P(S)\\frac{914}{1310} =\\) 0.6977099 This approximation will hinder the process of data mining and, eventually, the generation of a machine learning model for survival prediction. 4.2.3.3 Fixing the Problem By using stratified sampling we can raise the probability for the group that boarded in Queenstown and survived to be selected, therefore, taken in consideration for the generation of a survival prediction model. For this we will use conditional probability: \\(P(Survived|EmbarkedQ)= \\frac{P(Survived\\cap EmbarkedQ)}{P(EmbarkedQ)} = \\frac{44}{123}=\\) 0.3577236 library(dplyr) Q&lt;-filter(titanic, embarked == &quot;Q&quot; &amp; survived == 1) count(Q) ## # A tibble: 1 × 1 ## n ## &lt;int&gt; ## 1 44 "]
]
